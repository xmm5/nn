{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d6397e8",
   "metadata": {},
   "source": [
    "## Домашнее задание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ded92e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c412ef",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Написать на PyTorch глубокую сеть. Проверить работу форвард пасса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "474ab42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  6.3952, 329.3635, 454.4962, 409.9790, 532.8957],\n",
      "        [522.9081, 499.9833,  50.1889, 404.6904, 208.7615],\n",
      "        [293.3083, 890.0977, 492.7313, 868.4861, 137.8860],\n",
      "        [779.5287, 151.2042, 943.6721, 357.4485,  10.5112],\n",
      "        [277.2455, 236.5376,  90.7323, 419.2945, 255.7399],\n",
      "        [119.8963, 266.1962, 610.3841, 413.8224, 718.3633],\n",
      "        [208.7204, 275.9456, 303.2254,  60.9535, 872.4162],\n",
      "        [685.1585,  34.5945, 669.6101, 147.5503, 528.4401],\n",
      "        [237.0388, 951.6686, 662.2918, 580.3412, 656.7741],\n",
      "        [218.0410, 621.0591, 160.1076, 523.8544, 740.9001],\n",
      "        [ 80.5362, 161.0751, 245.4477, 409.2427, 944.0784],\n",
      "        [825.5128,  33.4292, 540.4025,  87.0882, 598.5329],\n",
      "        [650.4810,  18.0998, 554.7383, 575.9193, 681.9518],\n",
      "        [ 80.3514, 914.2291, 850.0707, 873.7661, 437.8051],\n",
      "        [919.5980, 208.3179, 654.8114,   1.0811, 881.9232]]) torch.Size([15, 5]) 2 torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Генерация бачей.\n",
    "samples = np.random.uniform(low=0.0, high=1000.0, size=(15,5))\n",
    "\n",
    "batch = torch.Tensor(samples)\n",
    "print(batch, batch.size(), batch.dim(), batch.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59899ba",
   "metadata": {},
   "source": [
    "<img src=\"./data/Deep%20Convolutional%20Network%20%28DCN%29.png\" width=\"640\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bee12c9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2670, -0.3398,  0.5421],\n",
       "        [ 0.2671, -0.3398,  0.5421],\n",
       "        [ 0.2670, -0.3399,  0.5421],\n",
       "        [ 0.2670, -0.3399,  0.5421],\n",
       "        [ 0.2671, -0.3398,  0.5421],\n",
       "        [ 0.2671, -0.3398,  0.5421],\n",
       "        [ 0.2671, -0.3398,  0.5421],\n",
       "        [ 0.2671, -0.3398,  0.5421],\n",
       "        [ 0.2670, -0.3398,  0.5421],\n",
       "        [ 0.2671, -0.3398,  0.5421],\n",
       "        [ 0.2671, -0.3398,  0.5421],\n",
       "        [ 0.2671, -0.3398,  0.5421],\n",
       "        [ 0.2671, -0.3398,  0.5421],\n",
       "        [ 0.2670, -0.3399,  0.5421],\n",
       "        [ 0.2671, -0.3398,  0.5421]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep Convolutional Network (DCN)\n",
    "    \"\"\"\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(5, 5)\n",
    "        self.activation1 = nn.Sigmoid()\n",
    "        self.layer2 = nn.Linear(5, 4)\n",
    "        self.activation2 = nn.Sigmoid()\n",
    "        self.layer3 = nn.Linear(4, 3)\n",
    "        self.activation3 = nn.Sigmoid()\n",
    "        self.layer4 = nn.Linear(3, 2)\n",
    "        self.activation4 = nn.Sigmoid()\n",
    "        self.layer5 = nn.Linear(2, 4)\n",
    "        self.activation5 = nn.ReLU()\n",
    "        self.layer6 = nn.Linear(4, 4)\n",
    "        self.activation6 = nn.ReLU()\n",
    "        self.layer7 = nn.Linear(4, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation1(self.layer1(x))\n",
    "        x = self.activation2(self.layer2(x))\n",
    "        x = self.activation3(self.layer3(x))\n",
    "        x = self.activation4(self.layer4(x))\n",
    "        x = self.activation5(self.layer5(x))\n",
    "        x = self.activation6(self.layer6(x))\n",
    "        x = self.layer7(x)\n",
    "        return x\n",
    "\n",
    "model = TestModel()\n",
    "model.train()\n",
    "model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f687f55c",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Написать адаптивный оптимизатор.\n",
    "\n",
    "**Оптимизатор. RMSprop**  \n",
    "\n",
    "```\n",
    "accumulated += rho (0.9-0.99) * accumulated + (1 - rho) * gradient ** 2\n",
    "adapt_lr = lr / sqrt(accumulated)\n",
    "w = w — adapt_lr * gradient\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e027bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSprop:\n",
    "    \"\"\"\n",
    "    accumulated += rho (0.9-0.99) * accumulated + (1 - rho) * gradient ** 2\n",
    "    adapt_lr = lr / sqrt(accumulated)\n",
    "    w = w — adapt_lr * gradient\n",
    "    \"\"\"\n",
    "    def __init__(self, model: nn.Linear, lr=0.001, rho=0.99, momentum=0.99):\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.rho = rho\n",
    "        self.acc_w = np.zeros_like(model.w)\n",
    "        self.acc_b = np.zeros_like(model.b)\n",
    "\n",
    "    def step(self):\n",
    "        self.acc_w += self.rho * self.acc_w + (1.0 - self.rho) * (self.model.d_w ** 2)\n",
    "        self.acc_b += self.rho * self.acc_b + (1.0 - self.rho) * (self.model.d_b ** 2)\n",
    "        \n",
    "        adapt_lr_w = self.lr / sqrt(self.acc_w)\n",
    "        adapt_lr_b = self.lr / sqrt(self.acc_b)\n",
    "        \n",
    "        self.model.w = self.model.w - adapt_lr_w * self.model.d_w\n",
    "        self.model.b = self.model.b - adapt_lr_b * self.model.d_b\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.model.d_w = np.zeros_like(self.model.d_w)\n",
    "        self.model.d_b = np.zeros_like(self.model.d_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e92918",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Решить задачу нахождения корней квадратного уравнения методом градиентного спуска.\n",
    "\n",
    "Ишем корни уравнения $x^2 - 6 \\cdot x + 4 = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44752315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество корней: 2\n",
      "минимум НЕ найден: x_start=0, lr=0.1, steps=1000\n",
      "минимум 0.764 найден: x_start=0, lr=0.01, steps=20\n",
      "минимум 0.764 найден: x_start=0, lr=0.001, steps=187\n",
      "минимум 5.236 найден: x_start=5, lr=0.01, steps=20\n",
      "минимум 5.236 найден: x_start=6, lr=0.01, steps=20\n",
      "минимум НЕ найден: x_start=10, lr=0.0001, steps=1000\n",
      "Второй корень уравнения: 5.236\n"
     ]
    }
   ],
   "source": [
    "a = 1\n",
    "b = -6\n",
    "c = 4\n",
    "\n",
    "def grad(x):\n",
    "    # Производная для уравнения (a * x^2 + b*x + c)^2\n",
    "    return 2 * (a * (x ** 2) + b * x + c) * (2 * a * x + b)\n",
    "    \n",
    "\n",
    "def find_x1_root(x_start, lr=1e-3, precision=1e-5, step=1000):\n",
    "    state_found = False\n",
    "    n_steps = 0\n",
    "    x = x_start\n",
    "    for i in range(step):\n",
    "        x_curr = x\n",
    "        x = x - lr * grad(x)\n",
    "\n",
    "        n_steps = i + 1\n",
    "\n",
    "        if abs(x - x_curr) < precision:\n",
    "            state_found = True\n",
    "            break\n",
    "\n",
    "    if state_found:\n",
    "        print(f'минимум {x:.3f} найден: x_start={x_start}, lr={lr}, steps={n_steps}')\n",
    "    else:\n",
    "        print(f'минимум НЕ найден: x_start={x_start}, lr={lr}, steps={n_steps}')\n",
    "        \n",
    "    return x\n",
    "\n",
    "def num_roots():\n",
    "    d = b^2 - 4*a*c\n",
    "    if d > 0:\n",
    "        return 2\n",
    "    elif d == 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def find_x2_root(x1):\n",
    "    # Второй корень ищется по теореме Виета (если уравнение имеет 2-а различных корня)\n",
    "    return -(b/a) - x1\n",
    "\n",
    "print(f'Количество корней: {num_roots()}')\n",
    "\n",
    "find_x1_root(0, 1e-1)\n",
    "x1 = find_x1_root(0, 1e-2)\n",
    "find_x1_root(0, 1e-3)\n",
    "find_x1_root(5, 1e-2)\n",
    "find_x1_root(6, 1e-2)\n",
    "find_x1_root(10, 1e-4)\n",
    "\n",
    "# В данном случае уравнение имеет 2-а различных корня\n",
    "print(f'Второй корень уравнения: {find_x2_root(x1):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5324758d",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "\n",
    "1. Всегда ли сойдемся за приемлемое количество шагов?  \n",
    "Если правильно выбрать начальную точку и лернинг рейт, то можно сойтись за приемлемое количество шагов.\n",
    "\n",
    "2. Важна ли начальная точка?  \n",
    "Важно чтобы начальная точка была блише к минимуму.\n",
    "\n",
    "3. Как найти второй корень?  \n",
    "Второй корень ищется по теореме Виета (если уравнение имеет 2-а различных корня).\n",
    "\n",
    "4. Как вляет ЛР?  \n",
    "Да, лернинг рейт влияет на скорость приближения к минимуму."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
