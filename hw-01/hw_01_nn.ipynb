{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d6397e8",
   "metadata": {},
   "source": [
    "## Домашнее задание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ded92e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c412ef",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Написать на PyTorch глубокую сеть. Проверить работу форвард пасса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "474ab42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[116.1369, 746.0771, 519.6165, 716.3768,  32.1776],\n",
      "        [496.6722, 599.8477, 457.7296, 789.0613, 622.1443],\n",
      "        [142.0859,  25.7229, 404.7177, 595.1578, 489.3096],\n",
      "        [178.1713, 769.6541, 483.3534, 973.6365, 767.7343],\n",
      "        [967.2346, 956.6804, 243.5869, 964.2245, 261.6455],\n",
      "        [396.1648, 368.6633, 739.4695, 515.0351, 775.8729],\n",
      "        [372.0689, 514.3693, 677.1927, 388.8015, 626.9980],\n",
      "        [910.5991, 746.9720, 443.7657, 555.8637, 897.4891],\n",
      "        [848.0792, 490.1591, 460.3412, 651.9518, 448.3521],\n",
      "        [709.1456, 767.9954,  37.3802, 804.2241, 674.7280],\n",
      "        [387.8181, 976.7886, 158.6455, 850.2786, 478.3173],\n",
      "        [515.4023, 177.1944,  99.1818, 173.9888,   4.5867],\n",
      "        [629.2847, 361.1377, 303.4508, 715.5740, 636.0769],\n",
      "        [ 66.6064, 173.3002, 950.3172, 464.0774, 479.8605],\n",
      "        [565.1191, 339.9091, 566.9595, 318.1571,  10.6617]]) torch.Size([15, 5]) 2 torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Генерация бачей.\n",
    "samples = np.random.uniform(low=0.0, high=1000.0, size=(15,5))\n",
    "\n",
    "batch = torch.Tensor(samples)\n",
    "print(batch, batch.size(), batch.dim(), batch.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59899ba",
   "metadata": {},
   "source": [
    "<img src=\"./data/Deep%20Convolutional%20Network%20%28DCN%29.png\" width=\"640\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bee12c9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0263,  0.1230, -0.2510],\n",
       "        [-0.0263,  0.1230, -0.2510],\n",
       "        [-0.0263,  0.1231, -0.2510],\n",
       "        [-0.0263,  0.1230, -0.2510],\n",
       "        [-0.0263,  0.1230, -0.2510],\n",
       "        [-0.0263,  0.1231, -0.2510],\n",
       "        [-0.0263,  0.1231, -0.2510],\n",
       "        [-0.0263,  0.1231, -0.2510],\n",
       "        [-0.0263,  0.1231, -0.2510],\n",
       "        [-0.0263,  0.1230, -0.2510],\n",
       "        [-0.0263,  0.1230, -0.2510],\n",
       "        [-0.0263,  0.1231, -0.2510],\n",
       "        [-0.0263,  0.1231, -0.2510],\n",
       "        [-0.0264,  0.1231, -0.2510],\n",
       "        [-0.0263,  0.1231, -0.2510]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep Convolutional Network (DCN)\n",
    "    \"\"\"\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(5, 5)\n",
    "        self.activation1 = nn.Sigmoid()\n",
    "        self.layer2 = nn.Linear(5, 4)\n",
    "        self.activation2 = nn.Sigmoid()\n",
    "        self.layer3 = nn.Linear(4, 3)\n",
    "        self.activation3 = nn.Sigmoid()\n",
    "        self.layer4 = nn.Linear(3, 2)\n",
    "        self.activation4 = nn.Sigmoid()\n",
    "        self.layer5 = nn.Linear(2, 4)\n",
    "        self.activation5 = nn.ReLU()\n",
    "        self.layer6 = nn.Linear(4, 4)\n",
    "        self.activation6 = nn.ReLU()\n",
    "        self.layer7 = nn.Linear(4, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation1(self.layer1(x))\n",
    "        x = self.activation2(self.layer2(x))\n",
    "        x = self.activation3(self.layer3(x))\n",
    "        x = self.activation4(self.layer4(x))\n",
    "        x = self.activation5(self.layer5(x))\n",
    "        x = self.activation6(self.layer6(x))\n",
    "        x = self.layer7(x)\n",
    "        return x\n",
    "\n",
    "model = TestModel()\n",
    "model.train()\n",
    "model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f687f55c",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Написать адаптивный оптимизатор.\n",
    "\n",
    "**Оптимизатор. RMSprop**  \n",
    "\n",
    "```\n",
    "accumulated += rho (0.9-0.99) * accumulated + (1 - rho) * gradient ** 2\n",
    "adapt_lr = lr / sqrt(accumulated)\n",
    "w = w — adapt_lr * gradient\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e027bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSprop:\n",
    "    \"\"\"\n",
    "    accumulated += rho (0.9-0.99) * accumulated + (1 - rho) * gradient ** 2\n",
    "    adapt_lr = lr / sqrt(accumulated)\n",
    "    w = w — adapt_lr * gradient\n",
    "    \"\"\"\n",
    "    def __init__(self, model: nn.Linear, lr=0.001, rho=0.99, momentum=0.99):\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.rho = rho\n",
    "        self.acc_w = np.zeros_like(model.w)\n",
    "        self.acc_b = np.zeros_like(model.b)\n",
    "\n",
    "    def step(self):\n",
    "        self.acc_w += self.rho * self.acc_w + (1.0 - self.rho) * (self.model.d_w ** 2)\n",
    "        self.acc_b += self.rho * self.acc_b + (1.0 - self.rho) * (self.model.d_b ** 2)\n",
    "        \n",
    "        adapt_lr_w = self.lr / sqrt(self.acc_w)\n",
    "        adapt_lr_b = self.lr / sqrt(self.acc_b)\n",
    "        \n",
    "        self.model.w = self.model.w - adapt_lr_w * self.model.d_w\n",
    "        self.model.b = self.model.b - adapt_lr_b * self.model.d_b\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.model.d_w = np.zeros_like(self.model.d_w)\n",
    "        self.model.d_b = np.zeros_like(self.model.d_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e92918",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Решить задачу нахождения корней квадратного уравнения методом градиентного спуска.\n",
    "\n",
    "Ищем корни уравнения $x^2 - 6 \\cdot x + 4 = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44752315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество корней: 2\n",
      "минимум НЕ найден: x_start=0, lr=0.1, steps=1000\n",
      "минимум 0.764 найден: x_start=0, lr=0.01, steps=20\n",
      "минимум 0.764 найден: x_start=0, lr=0.001, steps=187\n",
      "минимум 5.236 найден: x_start=5, lr=0.01, steps=20\n",
      "минимум 5.236 найден: x_start=6, lr=0.01, steps=20\n",
      "минимум НЕ найден: x_start=10, lr=0.0001, steps=1000\n",
      "Второй корень уравнения: 5.236\n"
     ]
    }
   ],
   "source": [
    "a = 1\n",
    "b = -6\n",
    "c = 4\n",
    "\n",
    "def grad(x):\n",
    "    # Производная для уравнения (a * x^2 + b*x + c)^2\n",
    "    return 2 * (a * (x ** 2) + b * x + c) * (2 * a * x + b)\n",
    "    \n",
    "\n",
    "def find_x1_root(x_start, lr=1e-3, precision=1e-5, step=1000):\n",
    "    state_found = False\n",
    "    n_steps = 0\n",
    "    x = x_start\n",
    "    for i in range(step):\n",
    "        x_curr = x\n",
    "        x = x - lr * grad(x)\n",
    "\n",
    "        n_steps = i + 1\n",
    "\n",
    "        if abs(x - x_curr) < precision:\n",
    "            state_found = True\n",
    "            break\n",
    "\n",
    "    if state_found:\n",
    "        print(f'минимум {x:.3f} найден: x_start={x_start}, lr={lr}, steps={n_steps}')\n",
    "    else:\n",
    "        print(f'минимум НЕ найден: x_start={x_start}, lr={lr}, steps={n_steps}')\n",
    "        \n",
    "    return x\n",
    "\n",
    "def num_roots():\n",
    "    d = b^2 - 4*a*c\n",
    "    if d > 0:\n",
    "        return 2\n",
    "    elif d == 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def find_x2_root(x1):\n",
    "    # Второй корень ищется по теореме Виета (если уравнение имеет 2-а различных корня)\n",
    "    return -(b/a) - x1\n",
    "\n",
    "print(f'Количество корней: {num_roots()}')\n",
    "\n",
    "find_x1_root(0, 1e-1)\n",
    "x1 = find_x1_root(0, 1e-2)\n",
    "find_x1_root(0, 1e-3)\n",
    "find_x1_root(5, 1e-2)\n",
    "find_x1_root(6, 1e-2)\n",
    "find_x1_root(10, 1e-4)\n",
    "\n",
    "# В данном случае уравнение имеет 2-а различных корня\n",
    "print(f'Второй корень уравнения: {find_x2_root(x1):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5324758d",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "\n",
    "1. Всегда ли сойдемся за приемлемое количество шагов?  \n",
    "Если правильно выбрать начальную точку и лернинг рейт, то можно сойтись за приемлемое количество шагов.\n",
    "\n",
    "2. Важна ли начальная точка?  \n",
    "Важно чтобы начальная точка была ближе к минимуму.\n",
    "\n",
    "3. Как найти второй корень?  \n",
    "Второй корень ищется по теореме Виета (если уравнение имеет 2-а различных корня).\n",
    "\n",
    "4. Как вляет ЛР?  \n",
    "Да, лернинг рейт влияет на скорость приближения к минимуму."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
